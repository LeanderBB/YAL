#include "yal/yal.h"
#include "yal/io/bytestream.h"
#include "yal/lexer/tokens.h"
#include "yal/lexer/lexer.h"
#include <iostream>
/*!max:re2c*/

namespace yal {

    enum {
        kMaxBufferSize = 4096
    };

    struct Lexer::LexerState {
        uint8_t buffer[kMaxBufferSize + YYMAXFILL];
        uint8_t* limit = nullptr;
        uint8_t* current = nullptr;
        uint8_t* marker = nullptr;
        uint8_t* token = nullptr;
        size_t lineNum = 1;
        size_t streamReadOffset = std::numeric_limits<size_t>::max();
        size_t lineStartOffset = 0;
        size_t tokenLineStart =0;
        size_t tokenColumnStart = 0;
        bool eof = false;

        bool fill(const size_t size,
                  ByteStream& stream) {

            if (eof) {
                return false;
            }
            const size_t free = token - buffer;
            if (free < size) {
                return false;
            }
            streamReadOffset = static_cast<uintptr_t>(limit - token) + stream.getPosition();
            ::memmove(buffer, token, limit - token);
            limit -= free;
            current -= free;
            marker -= free;
            token -= free;
            limit += stream.read(limit, free);
            if (limit < buffer + kMaxBufferSize) {
                eof = true;
                memset(limit, 0, YYMAXFILL);
                limit += YYMAXFILL;
            }
            return true;
        }


        size_t getColumnOffsetStart() const {

            if ( streamReadOffset== std::numeric_limits<size_t>::max()) {
                return 0;
            }

           return streamReadOffset +
                static_cast<size_t>(reinterpret_cast<uintptr_t>(token)
                                    - reinterpret_cast<uintptr_t>(buffer))
                            - lineStartOffset;
        }

        size_t getColumnOffsetEnd() const {
           return streamReadOffset +
                static_cast<size_t>(reinterpret_cast<uintptr_t>(current)
                                    - reinterpret_cast<uintptr_t>(buffer))
                            - lineStartOffset;
        }

        size_t getStreamOffset() const {
            return streamReadOffset +
                 static_cast<size_t>(reinterpret_cast<uintptr_t>(token)
                                     - reinterpret_cast<uintptr_t>(buffer));
        }

        void updateLineStartOffset() {
            lineNum++;
            lineStartOffset = streamReadOffset +
                    static_cast<size_t>(reinterpret_cast<uintptr_t>(current)
                                        - reinterpret_cast<uintptr_t>(buffer));
        }

        void markScanBegin() {
            token = current;
            tokenLineStart = lineNum;
            tokenColumnStart = getColumnOffsetStart();
        }

        size_t getTokenLength() const {
            return  static_cast<size_t>(reinterpret_cast<uintptr_t>(current)
                                        - reinterpret_cast<uintptr_t>(token));
        }

    };

    Lexer::Lexer(ByteStream &stream):
        m_stream(stream),
        m_lexerState(createLexerState()),
        m_curToken()
    {
        m_lexerState->limit = m_lexerState->buffer + kMaxBufferSize;
        m_lexerState->current = m_lexerState->limit;
        m_lexerState->token =m_lexerState->limit;
        m_lexerState->marker = m_lexerState->limit;
        m_curToken.token = Token::TokenCount;
    }

    Lexer::~Lexer(){

    }

    void
    Lexer::setToken(const Token token,
                    const LexerState& state) {
        m_curToken.token = token;
        m_curToken.tokLen = state.getTokenLength();
        m_curToken.lineStart = state.tokenLineStart;
        m_curToken.lineEnd = state.lineNum;
        m_curToken.columnStart = state.tokenColumnStart;
        m_curToken.columnEnd =state.getColumnOffsetEnd();
        m_curToken.tokenOffsetInStream = state.getStreamOffset();
    }

    std::unique_ptr<Lexer::LexerState>
    Lexer::createLexerState(){
        return std::make_unique<Lexer::LexerState>();
    }

    Lexer::Status
    Lexer::re2cExecute() {
        for (;;) {
            m_lexerState->markScanBegin();
            /*!re2c
        re2c:define:YYCTYPE = "unsigned char";
        re2c:define:YYCURSOR = m_lexerState->current;
        re2c:define:YYMARKER = m_lexerState->marker;
        re2c:define:YYLIMIT = m_lexerState->limit;
        re2c:yyfill:enable = 1;
        re2c:define:YYFILL = "if (!m_lexerState->fill(@@, m_stream)) return Status::EOS;";
        re2c:define:YYFILL:naked = 1;

        end = "\x00";
        end { if (m_lexerState->limit - m_lexerState->token == YYMAXFILL) {return Status::EOS;} }
        /* common character classes */

            /* basic tokens */
            VAR = "var";
            LET = "let";
            TRUE = "true";
            FALSE= "false";
            AND = "and";
            OR = "or";
            NOT = "not";
            THIS = "this";
            FN = "fn";
            NEWLINE="\n";
            COLON = ":";
            SEMICOLON = ";";
            TYPE = "type";
            BEGIN_SCOPE = "{";
            END_SCOPE = "}";
            NAME = [a-zA-Z][a-zA-Z0-9]*;


            /* final rules */
            VAR  { setToken(Token::Var, *m_lexerState); return Status::Ok; }
            LET  { setToken(Token::Let, *m_lexerState);return Status::Ok; }
            TYPE { setToken(Token::Type, *m_lexerState); return Status::Ok;}
            TRUE  { setToken(Token::True, *m_lexerState); return Status::Ok; }
            FALSE  { setToken(Token::False, *m_lexerState); return Status::Ok; }
            AND  { setToken(Token::And, *m_lexerState); return Status::Ok; }
            OR  { setToken(Token::Or, *m_lexerState); return Status::Ok; }
            NOT  { setToken(Token::Not, *m_lexerState); return Status::Ok; }
            THIS  { setToken(Token::This, *m_lexerState);return Status::Ok; }
            FN  { setToken(Token::Function, *m_lexerState);return Status::Ok; }
            NEWLINE {m_lexerState->updateLineStartOffset(); continue;}

            COLON { setToken(Token::Colon, *m_lexerState); return Status::Ok;}
            SEMICOLON { setToken(Token::SemiColon, *m_lexerState); return Status::Ok;}
            BEGIN_SCOPE { setToken(Token::BeginScope, *m_lexerState); return Status::Ok;}
            END_SCOPE { setToken(Token::EndScope, *m_lexerState); return Status::Ok;}
            NAME { setToken(Token::Name, *m_lexerState); return Status::Ok;}
            [ \t]* {continue;}
            * { setToken(Token::TokenCount, *m_lexerState); return Status::Error;}
            */
        }

    }
}
